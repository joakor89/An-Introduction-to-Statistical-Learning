{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib .pyplot import subplots\n",
    "\n",
    "# StatsModel\n",
    "import statsmodels .api as sm\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn. discriminant_analysis import \\\n",
    "( LinearDiscriminantAnalysis as LDA ,\n",
    "QuadraticDiscriminantAnalysis as QDA)\n",
    "from sklearn. naive_bayes import GaussianNB\n",
    "from sklearn. preprocessing import StandardScaler\n",
    "from sklearn. neighbors import KNeighborsClassifier\n",
    "from sklearn. linear_model import LogisticRegression\n",
    "from sklearn. model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Libraries\n",
    "from ISLP import load_data\n",
    "from ISLP import confusion_table\n",
    "from ISLP.models import contrast\n",
    "from ISLP.models import ( ModelSpec as MS ,\n",
    "summarize )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Logistic Regression, LDA, QDA, & KNN\n",
    "\n",
    "### The Stock Market Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Smarket = load_data ('Smarket')\n",
    "\n",
    "Smarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking column's Name\n",
    "Smarket.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smarket.corr()\n",
    "\n",
    "corr = Smarket.drop(columns=\"Direction\").corr()\n",
    "\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Smarket2 = Smarket.copy()\n",
    "Smarket2[\"Direction\"] = Smarket2[\"Direction\"].map({\"Down\": 0, \"Up\": 1})\n",
    "\n",
    "corr = Smarket2.corr(numeric_only=True)\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Smarket2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Smarket2.plot(y='Volume', color=\"tomato\");\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "allvars = Smarket2.columns.drop (['Today', 'Direction', 'Year'])\n",
    "\n",
    "design = MS(allvars)\n",
    "\n",
    "X = design. fit_transform (Smarket)\n",
    "y = Smarket. Direction == 'Up'\n",
    "\n",
    "glm = sm.GLM(y,\n",
    "             X,\n",
    "             family=sm. families . Binomial ())\n",
    "\n",
    "results = glm.fit ()\n",
    "summarize (results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = results.predict()\n",
    "probs [:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array (['Down']*1250)\n",
    "\n",
    "labels[probs >0.5] = \"Up\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_table(labels, Smarket.Direction )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "(507+145) /1250, np.mean(labels == Smarket. Direction )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = (Smarket2.Year < 2005)\n",
    "\n",
    "Smarket_train = Smarket2.loc[train]\n",
    "Smarket_test = Smarket2.loc[~train]\n",
    "\n",
    "Smarket_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test = X.loc[train], X.loc[~train]\n",
    "\n",
    "y_train , y_test = y.loc[train], y.loc[~train]\n",
    "\n",
    "glm_train = sm.GLM(y_train,\n",
    "                   X_train,\n",
    "                   family=sm. families . Binomial ())\n",
    "\n",
    "results = glm_train.fit()\n",
    "probs = results.predict(exog=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Smarket2.Direction\n",
    "\n",
    "L_train , L_test = D.loc[train], D.loc[~train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = np.array (['Down']*252)\n",
    "\n",
    "# labels[probs >0.5] = 'Up'\n",
    "\n",
    "# confusion_table(labels, L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Predicciones con etiquetas originales\n",
    "labels = np.array(['Down'] * len(probs))\n",
    "labels[probs > 0.5] = 'Up'\n",
    "\n",
    "# 2) Aseguramos que las verdaderas también sean 'Down'/'Up'\n",
    "true_labels = pd.Series(L_test).replace({\n",
    "    0: 'Down', 1: 'Up',\n",
    "    '0': 'Down', '1': 'Up'\n",
    "}).astype(str)\n",
    "\n",
    "# 3) Alineamos y eliminamos cualquier fila problemática (NaN)\n",
    "df_eval = pd.DataFrame({'pred': labels, 'true': true_labels}).dropna()\n",
    "\n",
    "# 4) Matriz de confusión con etiquetas originales\n",
    "cm = confusion_table(df_eval['pred'], df_eval['true'], labels=['Down', 'Up'])\n",
    "\n",
    "# 5) Accuracy\n",
    "acc = (df_eval['pred'].to_numpy() == df_eval['true'].to_numpy()).mean()\n",
    "\n",
    "print(cm)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "labels = labels[:len(L_test.values)]  # Truncate labels to match L_test.values length\n",
    "\n",
    "# Option 2: If they should be the same size but might be shaped differently\n",
    "labels = labels.reshape(-1)  # Flatten to 1D array\n",
    "L_test_values = L_test.values.reshape(-1)  # Flatten to 1D array\n",
    "\n",
    "print(\"Accuracy:\", (labels == L_test_values).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MS(['Lag1', 'Lag2']).fit(Smarket2)\n",
    "\n",
    "X = model. transform(Smarket2)\n",
    "X_train , X_test = X.loc[train], X.loc[~train]\n",
    "\n",
    "glm_train = sm.GLM(y_train,\n",
    "                   X_train,\n",
    "                   family=sm.families.Binomial())\n",
    "\n",
    "results = glm_train.fit()\n",
    "probs = results.predict(exog=X_test)\n",
    "labels = np.array (['Down']*252)\n",
    "labels[probs >0.5] = 'Up'\n",
    "\n",
    "confusion_table (pred_str, true_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "(35+106) /252, 106/(106+76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = pd. DataFrame ({'Lag1':[1.2 , 1.5] ,\n",
    "                          'Lag2':[1.1 , -0.8]});\n",
    "\n",
    "newX = model.transform(newdata)\n",
    "\n",
    "results.predict(newX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LDA( store_covariance =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train , X_test = [M.drop(columns =['intercept'])\n",
    "                    \n",
    "for M in [X_train , X_test ]]\n",
    "lda.fit(X_train , L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda. classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.priors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda. scalings_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_pred = lda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_table (lda_pred, L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_prob = lda. predict_proba (X_test)\n",
    "\n",
    "np.all(\n",
    "    np.where( lda_prob [: ,1] >= 0.5, 'Up','Down') == lda_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(\n",
    "    [lda.classes_ [i] for i in np.argmax(lda_prob , 1)] ==\n",
    "    lda_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(lda_prob [: ,0] > 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "qda = QDA( store_covariance =True)\n",
    "\n",
    "qda.fit(X_train , L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "qda.means_ , qda.priors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "qda. covariance_ [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "qda_pred = qda.predict(X_test)\n",
    "\n",
    "confusion_table (qda_pred , L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean( qda_pred == L_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = GaussianNB()\n",
    "\n",
    "NB.fit(X_train, L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB.class_prior_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB.theta_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[L_train == 'Down'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[L_train == 'Down ']. var(ddof =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_labels = NB.predict(X_test)\n",
    "\n",
    "confusion_table (nb_labels , L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB. predict_proba (X_test)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsClassifier ( n_neighbors =1)\n",
    "knn1.fit(X_train , L_train)\n",
    "knn1_pred = knn1.predict(X_test)\n",
    "\n",
    "confusion_table (knn1_pred , L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "(83+43) /252 , np.mean( knn1_pred == L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn3 = KNeighborsClassifier ( n_neighbors =3)\n",
    "knn3_pred = knn3.fit(X_train , L_train).predict(X_test)\n",
    "np.mean( knn3_pred == L_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "Caravan = load_data ('Caravan')\n",
    "\n",
    "Purchase = Caravan. Purchase\n",
    "Purchase.value_counts ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "348 / 5822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df = Caravan.drop(columns =['Purchase'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(with_mean =True,\n",
    "                        with_std =True,\n",
    "                        copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(feature_df)\n",
    "\n",
    "X_std = scaler.transform(feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_std = pd. DataFrame(X_std,\n",
    "                            columns= feature_df .columns);\n",
    "\n",
    "feature_std.std ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test,\n",
    " y_train,\n",
    " y_test) = train_test_split (feature_std,\n",
    "                             Purchase,\n",
    "                             test_size =1000,\n",
    "                             random_state =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn1 = KNeighborsClassifier(n_neighbors =1)\n",
    "knn1_pred = knn1.fit(X_train , y_train).predict(X_test)\n",
    "\n",
    "np.mean(y_test != knn1_pred), np.mean(y_test != \"No\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_table(knn1_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "9/(53+9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "for K in range(1 ,6):\n",
    "    knn = KNeighborsClassifier(n_neighbors =K)\n",
    "    knn_pred = knn.fit(X_train , y_train).predict(X_test)\n",
    "    C = confusion_table (knn_pred , y_test)\n",
    "    templ = ('K={0:d}: # predicted to rent: {1: >2} ,' +\n",
    "             '# who did rent {2:d}, accuracy {3:.1%}')\n",
    "    pred = C.loc['Yes'].sum ()\n",
    "    did_rent = C.loc['Yes','Yes']\n",
    "    print(templ.format(\n",
    "        K,\n",
    "        pred,\n",
    "        did_rent,\n",
    "        did_rent / pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit = LogisticRegression (C=1e10 , solver='liblinear')\n",
    "logit.fit(X_train , y_train)\n",
    "logit_pred = logit. predict_proba (X_test)\n",
    "logit_labels = np.where( logit_pred [: ,1] > 5, 'Yes', 'No')\n",
    "\n",
    "confusion_table (logit_labels , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_labels = np.where( logit_pred [: ,1] >0.25 , 'Yes', 'No')\n",
    "\n",
    "confusion_table (logit_labels , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "9/(20+9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "### Linear & Poisson Regression on the Bikeshare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bike = load_data ('Bikeshare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bike.shape, Bike.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = MS(['mnth',\n",
    "        'hr',\n",
    "        'workingday',\n",
    "        'temp',\n",
    "        'weathersit']).fit_transform (Bike)\n",
    "\n",
    "Y = Bike['bikers']\n",
    "M_lm = sm.OLS(Y, X).fit ()\n",
    "summarize (M_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_encode = contrast ('hr', 'sum')\n",
    "\n",
    "mnth_encode = contrast ('mnth', 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X2 = MS([ mnth_encode,\n",
    "#           hr_encode,\n",
    "#           'workingday',\n",
    "#           'temp',\n",
    "#           'weathersit ']). fit_transform (Bike)\n",
    "\n",
    "# M2_lm = sm.OLS(Y, X2).fit ()\n",
    "# S2 = summarize (M2_lm)\n",
    "# S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = MS([ mnth_encode,\n",
    "          hr_encode,\n",
    "          'workingday',\n",
    "          'temp',\n",
    "          'weathersit']). fit_transform (Bike)  \n",
    "\n",
    "M2_lm = sm.OLS(Y, X2).fit()\n",
    "S2 = summarize(M2_lm)\n",
    "S2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum((M_lm. fittedvalues - M2_lm. fittedvalues)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(M_lm.fittedvalues , M2_lm. fittedvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_month = S2[S2.index.str.contains ('mnth')]['coef']\n",
    "\n",
    "coef_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "months = Bike['mnth'].dtype.categories\n",
    "\n",
    "coef_month = pd.concat ([\n",
    "coef_month,\n",
    "pd.Series ([- coef_month .sum ()],\n",
    "           index =['mnth[Dec]'])\n",
    "])\n",
    "\n",
    "coef_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_month, ax_month = subplots(figsize=(8, 8))\n",
    "\n",
    "x_month = np.arange(coef_month.shape[0])\n",
    "\n",
    "ax_month.plot(x_month, coef_month, marker='o', ms=10)\n",
    "ax_month.set_xticks(x_month)\n",
    "ax_month.set_xticklabels([l[5] for l in coef_month.index], fontsize=20)\n",
    "\n",
    "ax_month.set_xlabel('Month', fontsize=20)\n",
    "ax_month.set_ylabel('Coefficient', fontsize=20)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_hr = S2[S2.index.str.contains ('hr')]['coef']\n",
    "\n",
    "coef_hr = coef_hr.reindex (['hr [{0}] '.format(h) for h in range (23) ])\n",
    "coef_hr = pd.concat ([ coef_hr,\n",
    "                       pd.Series ([- coef_hr.sum ()], index =['hr [23] '])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_hr , ax_hr = subplots(figsize =(8 ,8))\n",
    "\n",
    "x_hr = np.arange(coef_hr.shape [0])\n",
    "ax_hr.plot(x_hr , coef_hr , marker='o', ms =10)\n",
    "ax_hr. set_xticks (x_hr [::2])\n",
    "ax_hr. set_xticklabels (range (24) [::2] , fontsize =20)\n",
    "ax_hr. set_xlabel ('Hour', fontsize =20)\n",
    "ax_hr. set_ylabel ('Coefficient', fontsize =20);\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "#### Poisson Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88",
   "metadata": {},
   "outputs": [],
   "source": [
    "M_pois = sm.GLM(Y, X2 , family=sm. families .Poisson()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_pois = summarize (M_pois)\n",
    "coef_month = S_pois[S_pois.index.str.contains ('mnth ')]['coef']\n",
    "coef_month = pd.concat ([ coef_month ,\n",
    "pd.Series ([- coef_month .sum ()],\n",
    "index =['mnth[Dec]'])])\n",
    "coef_hr = S_pois[S_pois.index.str.contains ('hr')]['coef']\n",
    "coef_hr = pd.concat ([ coef_hr ,\n",
    "pd.Series ([- coef_hr.sum ()],\n",
    "index =['hr [23] '])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig_pois , (ax_month , ax_hr) = subplots (1, 2, figsize =(16 ,8))\n",
    "# ax_month .plot(x_month , coef_month , marker='o', ms =10)\n",
    "# ax_month . set_xticks (x_month)\n",
    "# ax_month . set_xticklabels ([l[5] for l in coef_month .index], fontsize=20)\n",
    "# ax_month . set_xlabel ('Month', fontsize =20)\n",
    "# ax_month . set_ylabel ('Coefficient', fontsize =20)\n",
    "# ax_hr.plot(x_hr , coef_hr , marker='o', ms =10)\n",
    "# ax_hr. set_xticklabels (range (24) [::2] , fontsize =20)\n",
    "# ax_hr. set_xlabel ('Hour', fontsize =20)\n",
    "# ax_hr. set_ylabel ('Coefficient', fontsize =20);\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax = subplots (figsize =(8, 8))\n",
    "ax.scatter(M2_lm.fittedvalues,\n",
    "           M_pois.fittedvalues, s=20)\n",
    "ax. set_xlabel ('Linear Regression Fit', fontsize =20)\n",
    "ax. set_ylabel ('Poisson Regression Fit', fontsize =20)\n",
    "ax.axline ([0 ,0] , c='black', linewidth =3,\n",
    "linestyle ='--', slope =1);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ISLP] *",
   "language": "python",
   "name": "conda-env-ISLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
