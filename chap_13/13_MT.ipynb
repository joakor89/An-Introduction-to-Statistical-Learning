{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Multiple Testing\n",
    "\n",
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Computing\n",
    "import numpy as np\n",
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# StatsModels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multitest import multipletests as mult_test\n",
    "\n",
    "# SciPy\n",
    "from scipy.stats import (ttest_1samp, ttest_rel, ttest_ind, t as t_dbn)\n",
    "\n",
    "# ISLP\n",
    "from ISLP import load_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Review of Hypothesis Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(12)\n",
    "\n",
    "X = rng.standard_normal((10, 100))\n",
    "\n",
    "true_mean = np.array([0.5]*50 + [0]*50)\n",
    "\n",
    "X += true_mean[None, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ttest_1samp (X[:,0], 0)\n",
    "result.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values = np.empty(100)\n",
    "\n",
    "for i in range(100):\n",
    "    p_values [i] = ttest_1samp(X[:, i], 0).pvalue\n",
    "    decision = pd.cut(p_values,\n",
    "                      [0, 0.05, 1],\n",
    "                      labels =['Reject H0',\n",
    "                               'Do not reject H0'])\n",
    "\n",
    "truth = pd.Categorical(true_mean == 0,\n",
    "                       categories =[True, False],\n",
    "                       ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(decision,\n",
    "            truth,\n",
    "            rownames =['Decision'],\n",
    "            colnames =['H0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mean = np.array([1]*50 + [0]*50)\n",
    "\n",
    "X = rng.standard_normal((10, 100))\n",
    "X += true_mean [None, :]\n",
    "\n",
    "for i in range(100):\n",
    "    p_values[i] = ttest_1samp(X[:, i], 0).pvalue\n",
    "    decision = pd.cut(p_values,\n",
    "                      [0, 0.05, 1],\n",
    "                      labels =['Reject H0',\n",
    "                               'Do not reject H0'])\n",
    "\n",
    "truth = pd.Categorical(true_mean == 0,\n",
    "                       categories=[True, False],\n",
    "                       ordered=True)\n",
    "pd. crosstab (decision,\n",
    "              truth,\n",
    "              rownames =['Decision'],\n",
    "              colnames =['H0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Family-Wise Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.linspace(1, 501)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "[ax.plot(m,\n",
    "         1 - (1 - alpha)**m,\n",
    "         label=r'$\\alpha =%s$' % str(alpha))\n",
    "\n",
    "for alpha in [0.05, 0.01, 0.001]]\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('Number of Hypotheses')\n",
    "ax.set_ylabel('Family -Wise Error Rate')\n",
    "ax.legend()\n",
    "ax.axhline(0.05, c='k', ls='--');\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "Fund = load_data('Fund')\n",
    "fund_mini = Fund.iloc[:, :5]\n",
    "fund_mini_pvals = np.empty(5)\n",
    "\n",
    "for i in range(5):\n",
    "    fund_mini_pvals[i] = ttest_1samp(fund_mini.iloc[:, i], 0).pvalue\n",
    "\n",
    "fund_mini_pvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "reject, bonf = mult_test(fund_mini_pvals, method = \"bonferroni\")[:2]\n",
    "\n",
    "reject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "bonf, np.minimum(fund_mini_pvals * 5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_test(fund_mini_pvals, method = \"holm\", alpha =0.05)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_mini.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_rel(fund_mini['Manager1'],\n",
    "          fund_mini ['Manager2']).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = np.hstack([fund_mini.iloc[:, i] for i in range(5)])\n",
    "\n",
    "managers = np.hstack([[i+1]*50 for i in range(5)])\n",
    "\n",
    "tukey = pairwise_tukeyhsd(returns, managers)\n",
    "print(tukey.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8 ,8))\n",
    "\n",
    "tukey.plot_simultaneous(ax=ax);\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### False Discovery Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_pvalues = np.empty (2000)\n",
    "\n",
    "for i, manager in enumerate(Fund.columns):\n",
    "    fund_pvalues[i] = ttest_1samp(Fund[manager], 0).pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fund_qvalues = mult_test(fund_pvalues, method = \"fdr_bh\")[1]\n",
    "\n",
    "fund_qvalues [:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fund_qvalues <= 0.1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "(fund_pvalues <= 0.1 / 2000).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ = np.sort(fund_pvalues\n",
    "                 )\n",
    "m = fund_pvalues.shape[0]\n",
    "q = 0.1\n",
    "\n",
    "sorted_set_ = np.where(sorted_ < q * np. linspace (1, m, m) / m)[0]\n",
    "\n",
    "if sorted_set_ .shape[0] > 0:\n",
    "    selected_ = fund_pvalues < sorted_[sorted_set_].max()\n",
    "    sorted_set_ = np.arange(sorted_set_ .max())\n",
    "else:\n",
    "    selected_ = []\n",
    "    sorted_set_ = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(np.arange(0, sorted_.shape[0]) + 1,\n",
    "           sorted_,\n",
    "           s=10)\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xscale('log')\n",
    "ax.set_ylabel('P-Value')\n",
    "ax.set_xlabel('Index')\n",
    "ax.scatter(sorted_set_ +1, sorted_[ sorted_set_], c='r', s=20)\n",
    "ax.axline ((0, 0), (1,q/m), c='k', ls='--', linewidth =3);\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### A Re-Sampling Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "Khan = load_data('Khan')\n",
    "\n",
    "D = pd.concat([ Khan['xtrain'], Khan['xtest']])\n",
    "D['Y'] = pd.concat([Khan['ytrain'], Khan['ytest']])\n",
    "D['Y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "D2 = D[lambda df:df['Y'] == 2]\n",
    "D4 = D[lambda df:df['Y'] == 4]\n",
    "\n",
    "gene_11 = 'G0011'\n",
    "\n",
    "observedT, pvalue = ttest_ind(D2[gene_11],\n",
    "                              D4[gene_11],\n",
    "                              equal_var=True)\n",
    "observedT, pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 10000\n",
    "\n",
    "Tnull = np.empty(B)\n",
    "\n",
    "D_ = np.hstack ([D2[gene_11], D4[gene_11]])\n",
    "n_ = D2[gene_11].shape[0]\n",
    "D_null = D_.copy()\n",
    "\n",
    "for b in range(B):\n",
    "    rng.shuffle(D_null)\n",
    "    ttest_ = ttest_ind(D_null[:n_],\n",
    "                       D_null[n_:],\n",
    "                       equal_var=True)\n",
    "\n",
    "Tnull[b] = ttest_.statistic\n",
    "(np.abs(Tnull) > np.abs(observedT)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "ax.hist(Tnull,\n",
    "        bins =100,\n",
    "        density=True,\n",
    "        facecolor ='y',\n",
    "        label='Null')\n",
    "\n",
    "xval = np.linspace(-4.2, 4.2, 1001)\n",
    "ax.plot(xval,\n",
    "        t_dbn.pdf(xval, D_.shape[0] -2),\n",
    "        c='r')\n",
    "\n",
    "ax.axvline(observedT,\n",
    "           c='b',\n",
    "           label='Observed')\n",
    "\n",
    "ax.legend()\n",
    "ax. set_xlabel(\"Null Distribution of Test Statistic\");\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "m, B = 100, 10000\n",
    "\n",
    "idx = rng.choice(Khan['xtest'].columns, m, replace=False)\n",
    "T_vals = np.empty(m)\n",
    "Tnull_vals = np.empty((m, B))\n",
    "\n",
    "for j in range(m):\n",
    "    col = idx[j]\n",
    "    T_vals[j] = ttest_ind (D2[col],\n",
    "                           D4[col],\n",
    "                           equal_var=True).statistic\n",
    "    D_ = np.hstack([D2[col], D4[col]])\n",
    "\n",
    "D_null = D_.copy()\n",
    "\n",
    "for b in range(B):\n",
    "    rng.shuffle(D_null)\n",
    "ttest_ = ttest_ind(D_null[:n_],\n",
    "                   D_null[n_:],\n",
    "                   equal_var=True)\n",
    "\n",
    "Tnull_vals[j,b] = ttest_.statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = np.sort(np.abs(T_vals))\n",
    "FDRs, Rs, Vs = np.empty((3, m))\n",
    "\n",
    "for j in range(m):\n",
    "    R = np.sum(np.abs(T_vals) >= cutoffs[j])\n",
    "    V = np.sum(np.abs(Tnull_vals) >= cutoffs[j]) / B\n",
    "    Rs[j] = R\n",
    "    Vs[j] = V\n",
    "    FDRs[j] = V / R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(idx[np.abs(T_vals) >= cutoffs[FDRs < 0.1].min()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(idx[np.abs(T_vals) >= cutoffs[FDRs < 0.2].min()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig , ax = plt.subplots()\n",
    "\n",
    "ax.plot(Rs, FDRs, 'b', linewidth =3)\n",
    "ax.set_xlabel(\"Number of Rejections\")\n",
    "ax.set_ylabel(\"False Discovery Rate\");\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ISLP] *",
   "language": "python",
   "name": "conda-env-ISLP-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
